<!--### Hi there ðŸ‘‹



**lxtGH/lxtGH** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->


[![Website](https://img.shields.io/website?label=lxtgh.github.io&style=for-the-badge&up_message=up&url=https://lxtgh.github.io/)](https://lxtgh.github.io/)
[![GitHub Stars](https://img.shields.io/github/stars/lxtGH?affiliations=OWNER%2CCOLLABORATOR&style=for-the-badge)](https://github.com/lxtGH)

![]( https://steins-gate-visitor-count.greenhandatsjtu.repl.co/{lxtGH})

My name is Xiangtai. My research focuses on computer vision, deep learning, and multi-modal models.

Currently, I am working as a Research Scientist at Bytedance Seed in SG.

I was a research fellow at MMlab@NTU, supervised by [Prof. Chen Change Loy](https://www.mmlab-ntu.com/person/ccloy/). I have worked as a research scientist/associate at various places before, including JD, Sensetime, and Shanghai AI Laboratory. I obtained my Ph.D. from Peking University.

My published works are on my [homepage](https://lxtgh.github.io/), and I am open to discussing potential remote collaborations on research. Please feel free to email me at xiangtai94@gmail.com.


I love coding and building universal, larger, efficient models (pure vision and multi-modal large language models). 


Moreover, most of my works, including the ones I have profoundly contributed to, are open-sourced on GitHub.
